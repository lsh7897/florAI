import os
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.embeddings import OpenAIEmbeddings

# ğŸ”¹ LangChain LLM ì„¤ì •
llm = ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), model="gpt-4")

def embed_query(query: str):
    embedder = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
    vector = embedder.embed_query(query)  # list[float]
    return [vector]  # faissëŠ” 2D array í•„ìš”

def generate_reason(query: str, description: str, flower_name: str):
    prompt = PromptTemplate(
        input_variables=["query", "description", "flower"],
        template="""
        ì‚¬ìš©ì ì˜ë„: {query}
        ê½ƒ ì„¤ëª…: {description}
        ì´ ê½ƒì´ '{query}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ìœ ë¥¼ ë‘ ë¬¸ì¥ì´ìƒìœ¼ë¡œ ì„¤ëª…í•´ì¤˜. ê½ƒ ì´ë¦„({flower})ë„ í¬í•¨í•´ì„œ êµ¬ë§¤ìë¥¼ ì¶©ë¶„íˆ ì„¤ë“ í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({
        "query": query,
        "description": description,
        "flower": flower_name
    }).strip()