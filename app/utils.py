import faiss
import json
import os
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.embeddings import OpenAIEmbeddings

# ğŸ”¹ ë²¡í„° ì¸ë°ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë³´ë‚´ì˜¤ê¸°
index = faiss.read_index("flower_index.faiss")
with open("flower_metadata.json", encoding="utf-8") as f:
    metadata_list = json.load(f)

# ğŸ”¹ LangChain LLM ì„¤ì •
llm = ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), model="gpt-3.5-turbo")

def embed_query(query: str):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ë¹„ì–´ ìˆì–´ìš”!")

    # ğŸ‘‰ ëª…ì‹œì ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ì–´ì„œ ë„˜ê¸°ê¸° (LangChain ë²„ê·¸ ë°©ì§€)
    embedder = OpenAIEmbeddings(openai_api_key=api_key)
    return embedder.embed_query(query).reshape(1, -1)

def generate_reason(query: str, description: str, flower_name: str):
    prompt = PromptTemplate(
        input_variables=["query", "description", "flower"],
        template="""
        ì‚¬ìš©ì ì˜ë„: {query}
        ê½ƒ ì„¤ëª…: {description}
        ì´ ê½ƒì´ '{query}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜. ê½ƒ ì´ë¦„({flower})ë„ í¬í•¨í•´ì„œ ìì „ì‹œê²Œ ì“°ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({
        "query": query,
        "description": description,
        "flower": flower_name
    }).strip()

def expand_keywords(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ: {keywords}
        ì´ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì •ê³¼ ìƒí™©ì„ í¬í•¨í•œ ìì „ì‹œëœ ë¬¸ì¥ìœ¼ë¡œ í™•ì¥í•´ì¤˜.
        ë„ˆë¬´ ê¸´ì§€ ì•Šê³ , ì˜ë„ê°€ ì˜ ë“¤ì–´ë‚  ìˆ˜ ìˆê²Œ ë§í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(keywords).strip()

def get_flower_recommendations(keywords: str, top_k: int = 3):
    expanded_query = expand_keywords(keywords)
    query_vector = embed_query(expanded_query)
    distances, indices = index.search(query_vector, 10)

    results = []
    seen = set()
    for idx in indices[0]:
        flower = metadata_list[idx]
        if flower["name"] in seen:
            continue
        seen.add(flower["name"])

        reason = generate_reason(expanded_query, flower["description"], flower["name"])
        results.append({
            "name": flower["name"],
            "description": flower["description"],
            "color": flower["color"],
            "season": flower["season"],
            "scent": flower["scent"],
            "reason": reason
        })

        if len(results) == top_k:
            break

    return {
        "expanded_query": expanded_query,
        "recommendations": results
    }
