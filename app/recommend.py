import faiss
import json
import os
import numpy as np
from app.utils import embed_query, generate_reason
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ğŸ”¹ ë²¡í„° ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
index = faiss.read_index("flower_index.faiss")
with open("flower_metadata.json", encoding="utf-8") as f:
    metadata_list = json.load(f)

# ğŸ”¹ LangChain LLM ì„¤ì •
llm = ChatOpenAI(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    model="gpt-3.5-turbo"
)

# ğŸ”¹ í‚¤ì›Œë“œ í™•ì¥ í•¨ìˆ˜
def expand_keywords(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ: {keywords}
        ì´ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì •ê³¼ ìƒí™©ì„ í¬í•¨í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í™•ì¥í•´ì¤˜.
        ë„ˆë¬´ ê¸¸ì§€ ì•Šê³ , ì˜ë„ê°€ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ ë§í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(keywords).strip()

# ğŸ”¹ ì¶”ì²œ í•¨ìˆ˜ (ë””ë²„ê¹… í¬í•¨, ì—ëŸ¬ ë°©ì§€ ì™„ë¹„)
def get_flower_recommendations(keywords: str, top_k: int = 3):
    print("ğŸ“¥ [ì‹œì‘] get_flower_recommendations()")
    print("ğŸ”¤ ì…ë ¥ í‚¤ì›Œë“œ:", keywords)

    # 1. í‚¤ì›Œë“œ í™•ì¥
    expanded_query = expand_keywords(keywords)
    print("ğŸª„ í™•ì¥ëœ ë¬¸ì¥:", expanded_query)

    # 2. ì„ë² ë”© ì²˜ë¦¬ + 2ì°¨ì› ë³€í™˜
    raw_vector = embed_query(expanded_query)
    print("ğŸ“¦ ì›ì‹œ ì„ë² ë”© ê¸¸ì´:", len(raw_vector))

    try:
        query_vector = np.array(raw_vector).reshape(1, -1)
    except Exception as e:
        print("âŒ query_vector ë³€í™˜ ì‹¤íŒ¨:", e)
        return {"error": f"query_vector ì—ëŸ¬: {e}"}

    print("ğŸ“ query_vector.shape:", query_vector.shape)

    # 3. FAISS ê²€ìƒ‰
    try:
        result = index.search(query_vector, 10)
        print("ğŸ” FAISS ê²€ìƒ‰ ê²°ê³¼:", result)
    except Exception as e:
        print("âŒ FAISS ê²€ìƒ‰ ì¤‘ ì—ëŸ¬:", e)
        return {"error": f"faiss.search ì—ëŸ¬: {e}"}

    # 4. ê²°ê³¼ ì–¸íŒ©
    if not isinstance(result, tuple) or len(result) != 2:
        return {"error": f"âŒ FAISS ê²°ê³¼ê°€ íŠœí”Œ ì•„ë‹˜: {result}"}

    distances, indices = result

    # 5. ê²°ê³¼ ì •ë¦¬
    results = []
    seen = set()
    for idx in indices[0]:
        flower = metadata_list[idx]
        if flower["name"] in seen:
            continue
        seen.add(flower["name"])

        reason = generate_reason(expanded_query, flower["description"], flower["name"])
        results.append({
            "name": flower["name"],
            "description": flower["description"],
            "color": flower["color"],
            "season": flower["season"],
            "scent": flower["scent"],
            "reason": reason
        })

        if len(results) == top_k:
            break

    return {
        "expanded_query": expanded_query,
        "recommendations": results
    }
