
import os
import numpy as np
import random
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

load_dotenv()

# Qdrant ì„¤ì •
qdrant = QdrantClient(
    url=os.getenv("QDRANT_HOST"),
    api_key=os.getenv("QDRANT_API_KEY")
)
COLLECTION_NAME = "flowers"

# ìž„ë² ë”© & LLM
embedder = OpenAIEmbeddings(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    model="text-embedding-ada-002"
)
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    model="gpt-3.5-turbo"
)

# ë¬¸ìž¥ ìƒì„±
def expand_query_desc(keywords: list[str]) -> tuple[str, list[str], list[str]]:
    base = (keywords + [""] * 5)[:5]
    target, emotion, detail, personality, gender = base

    desc = f"{target}ì—ê²Œ {emotion}({detail})ì˜ ê°ì •ì„ í‘œí˜„í•˜ê³  ì‹¶ì–´ìš”. ìƒëŒ€ëŠ” {gender}ì´ê³  {personality}ìž…ë‹ˆë‹¤."
    emotion_tags = [f"{emotion}({detail})"]
    style_keywords = [gender, personality]
    return desc, emotion_tags, style_keywords

# ì¶”ì²œ ì´ìœ  ìƒì„±
def generate_reason(query: str, description: str, flower_name: str) -> str:
    prompt = PromptTemplate(
        input_variables=["query", "description", "flower"],
        template="""
        ì‚¬ìš©ìž ì˜ë„: {query}
        ê½ƒ ì„¤ëª…: {description}
        ì´ ê½ƒì´ '{query}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ìœ ë¥¼ ë‘ ë¬¸ìž¥ì´ìƒìœ¼ë¡œ ì„¤ëª…í•´ì¤˜. ê½ƒ ì´ë¦„({flower})ë„ í¬í•¨í•´ì„œ êµ¬ë§¤ìžë¥¼ ì¶©ë¶„ížˆ ì„¤ë“ í•  ìˆ˜ ìžˆë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({
        "query": query,
        "description": description,
        "flower": flower_name
    }).strip()

# ì¶”ì²œ í•¨ìˆ˜
def get_flower_recommendations(keywords: list[str], top_k: int = 3, candidate_k: int = 15):
    desc_query, emotion_tags, style_keywords = expand_query_desc(keywords)
    desc_vec = embedder.embed_query(desc_query)

    print("ðŸ“Œ ì¿¼ë¦¬ ë¬¸ìž¥:", desc_query)

    results = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector={"name": "desc", "vector": desc_vec},
        limit=candidate_k
    )

    print("\nðŸ“Š í›„ë³´ ìœ ì‚¬ë„ ì ìˆ˜:")
    for r in results[:10]:
        print(f"  - {r.payload['name']}: {r.score:.4f}")

    scored = []
    for r in results:
        payload = r.payload
        score = r.score
        boost = 0.0

        # ê°ì • íƒœê·¸ ê°€ì¤‘ì¹˜ (ì •í™•ížˆ ì¼ì¹˜í•˜ëŠ” íƒœê·¸ê°€ ìžˆëŠ” ê²½ìš°)
        if any(tag in payload.get("emotion_tags", []) for tag in emotion_tags):
            boost += 0.05

        # ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ (ì„±í–¥/ì„±ë³„/ìƒ‰/í–¥ê¸° ë“±ì—ì„œ ì¼ì¹˜ ë‹¨ì–´ ì¡´ìž¬ì‹œ)
        if any(sk in payload.get("description", "") for sk in style_keywords):
            boost += 0.03

        scored.append((r, score + boost))

    # ìƒ˜í”Œë§ ê¸°ë°˜ ë‹¤ì–‘ì„± + ìµœì¢… ì ìˆ˜ ì •ë ¬
    scored = sorted(scored, key=lambda x: x[1], reverse=True)
    sampled = scored[:top_k * 2] if len(scored) >= top_k * 2 else scored

    final = []
    seen = set()
    for r, s in sampled:
        name = r.payload["name"]
        if name in seen:
            continue
        seen.add(name)

        reason = generate_reason(desc_query, r.payload["description"], name)
        final.append({
            "FLW_IDX": r.payload["FLW_IDX"],
            "name": name,
            "score": round(s, 4),
            "reason": reason
        })

        if len(final) >= top_k:
            break

    return {"recommendations": final}
