
import os
import numpy as np
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

load_dotenv()

# Qdrant í´ë¼ì´ì–¸íŠ¸
qdrant = QdrantClient(
    url=os.getenv("QDRANT_HOST"),
    api_key=os.getenv("QDRANT_API_KEY"),
)
COLLECTION_NAME = "flowers"

# ìž„ë² ë”©
embedder = OpenAIEmbeddings(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    model="text-embedding-ada-002"
)

# LLM
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    model="gpt-3.5-turbo"
)

# í‚¤ì›Œë“œ 5ê°œ: ëŒ€ìƒ, ê°ì •, ì„¸ë¶€ê°ì •, ì„±í–¥, ì„±ë³„
def expand_query_desc(keywords: list[str]) -> str:
    base = (keywords + [""] * 5)[:5]
    target, emotion, detail, personality, gender = base
    return f"{target}ì—ê²Œ {emotion}({detail})ì˜ ê°ì •ì„ í‘œí˜„í•˜ê³  ì‹¶ì–´ìš”. ìƒëŒ€ëŠ” {gender}ì´ê³  {personality}ìž…ë‹ˆë‹¤."

def generate_reason(query: str, description: str, flower_name: str) -> str:
    prompt = PromptTemplate(
        input_variables=["query", "description", "flower"],
        template="""
        ì‚¬ìš©ìž ì˜ë„: {query}
        ê½ƒ ì„¤ëª…: {description}
        ì´ ê½ƒì´ '{query}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ìœ ë¥¼ ë‘ ë¬¸ìž¥ì´ìƒìœ¼ë¡œ ì„¤ëª…í•´ì¤˜. ê½ƒ ì´ë¦„({flower})ë„ í¬í•¨í•´ì„œ êµ¬ë§¤ìžë¥¼ ì¶©ë¶„ížˆ ì„¤ë“ í•  ìˆ˜ ìžˆë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({
        "query": query,
        "description": description,
        "flower": flower_name
    }).strip()

def get_flower_recommendations(keywords: list[str], top_k: int = 3):
    desc_query = expand_query_desc(keywords)
    desc_vec = embedder.embed_query(desc_query)

    print("ðŸ“Œ ì¿¼ë¦¬ ë¬¸ìž¥:", desc_query)

    results = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector={"name": "desc", "vector": desc_vec},
        limit=top_k * 5
    )

    print("\nðŸ“Š ìœ ì‚¬ë„ ìƒìœ„ ê²°ê³¼:")
    for r in results[:5]:
        print(f"  - {r.payload['name']}: {r.score:.4f}")

    final = []
    seen = set()
    for r in sorted(results, key=lambda x: x.score, reverse=True):
        payload = r.payload
        name = payload["name"]
        if name in seen:
            continue
        seen.add(name)

        reason = generate_reason(desc_query, payload["description"], name)
        final.append({
            "FLW_IDX": payload["FLW_IDX"],
            "name": name,
            "score": round(r.score, 4),
            "reason": reason
        })

        if len(final) >= top_k:
            break

    return {"recommendations": final}
