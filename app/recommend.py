import faiss
import json
import os
import numpy as np
from app.utils import embed_query, generate_reason
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ğŸ”¹ FAISS ì¸ë±ìŠ¤ ë¡œë“œ (ë²¡í„°ë§Œ ì €ì¥)
index = faiss.read_index("flower_index.faiss")

# ğŸ”¹ ë©”íƒ€ë°ì´í„° ë¡œë“œ (ë²¡í„° ì—†ìŒ)
with open("flower_metadata.json", encoding="utf-8") as f:
    metadata_list = json.load(f)

# ğŸ”¹ LLM ì„¸íŒ…
llm = ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), model="gpt-3.5-turbo")

# ğŸ”¸ ê°ì • ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
def classify_emotion(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ë‹¤ìŒ í‚¤ì›Œë“œëŠ” ê½ƒì„ ì¶”ì²œë°›ê¸° ìœ„í•œ ìƒí™©ì…ë‹ˆë‹¤:
        {keywords}

        ì´ í‚¤ì›Œë“œì—ì„œ ëŠê»´ì§€ëŠ” ì¤‘ì‹¬ ê°ì •ì„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì¤˜ (ëª©ë¡ ì™¸ ê°ì •ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ):

        ì‚¬ë‘(ê³ ë°±), ì‚¬ë‘(ë¶€ëª¨), ì‚¬ë‘(ì˜ì›),
        ì´ë³„(ë¶„ë…¸), ì´ë³„(ìŠ¬í””), ì´ë³„(í™”í•´),
        ìˆœìˆ˜(ì‘ì›), ìˆœìˆ˜(ë¯¿ìŒ),
        ì¡´ê²½(ìš°ìƒ),
        í–‰ë³µ(ê¸°ì›), í–‰ë³µ(ì„±ê³µ)

        ì •í™•í•˜ê²Œ ìœ„ ëª©ë¡ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•´. ì´ìœ ëŠ” ì“°ì§€ ë§ê³ .
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    result = chain.run({"keywords": keywords}).strip()

    VALID_CATEGORIES = {
        "ì‚¬ë‘(ê³ ë°±)", "ì‚¬ë‘(ë¶€ëª¨)", "ì‚¬ë‘(ì˜ì›)",
        "ì´ë³„(ë¶„ë…¸)", "ì´ë³„(ìŠ¬í””)", "ì´ë³„(í™”í•´)",
        "ìˆœìˆ˜(ì‘ì›)", "ìˆœìˆ˜(ë¯¿ìŒ)",
        "ì¡´ê²½(ìš°ìƒ)",
        "í–‰ë³µ(ê¸°ì›)", "í–‰ë³µ(ì„±ê³µ)"
    }
    return result if result in VALID_CATEGORIES else "ì´ë³„(ìŠ¬í””)"

# ğŸ”¸ í‚¤ì›Œë“œ í™•ì¥
def expand_keywords(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ: {keywords}
        ì´ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì •ê³¼ ìƒí™©ì„ í¬í•¨í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í™•ì¥í•´ì¤˜.
        ë„ˆë¬´ ê¸¸ì§€ ì•Šê³ , ì˜ë„ê°€ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ ë§í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(keywords).strip()

# ğŸ”¹ ì¶”ì²œ ì‹œìŠ¤í…œ í•µì‹¬ í•¨ìˆ˜
def get_flower_recommendations(keywords: str, top_k: int = 3):
    expanded_query = expand_keywords(keywords)
    emotion_category = classify_emotion(keywords)
    query_vector = embed_query(expanded_query)

    # ğŸ” ê°ì •ì— í•´ë‹¹í•˜ëŠ” ê½ƒë§Œ í•„í„°ë§ (index ê¸°ë°˜)
    filtered_indices = [i for i, flower in enumerate(metadata_list)
                        if "emotion_tags" in flower and emotion_category in flower["emotion_tags"]]

    if not filtered_indices:
        return {
            "expanded_query": expanded_query,
            "emotion_category": emotion_category,
            "recommendations": [],
            "error": f"'{emotion_category}' ê°ì •ì— í•´ë‹¹í•˜ëŠ” ê½ƒì´ ì—†ìŠµë‹ˆë‹¤."
        }

    # ğŸ”§ FAISS ì„ì‹œ ì¸ë±ìŠ¤ êµ¬ì„± (í•„í„°ëœ ê²ƒë§Œ)
    dim = index.d
    sub_index = faiss.IndexFlatL2(dim)
    sub_vectors = [index.reconstruct(i) for i in filtered_indices]
    sub_index.add(np.array(sub_vectors).astype("float32"))

    distances, sub_idxs = sub_index.search(np.array(query_vector).astype("float32"), top_k)

    results = []
    for sub_i in sub_idxs[0]:
        real_index = filtered_indices[sub_i]
        flower = metadata_list[real_index]
        reason = generate_reason(expanded_query, flower["description"], flower["name"])
        results.append({
            "name": flower["name"],
            "description": flower["description"],
            "color": flower["color"],
            "season": flower["season"],
            "scent": flower["scent"],
            "reason": reason
        })

    return {
        "expanded_query": expanded_query,
        "emotion_category": emotion_category,
        "recommendations": results
    }
