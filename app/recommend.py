import faiss
import json
import os
import numpy as np
from app.utils import embed_query, generate_reason
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ğŸ”¹ FAISS ì¸ë±ìŠ¤ ë¡œë“œ (ë²¡í„°ë§Œ ì €ì¥)
index = faiss.read_index("flower_index.faiss")

# Load metadata
with open("flower_metadata.json", encoding="utf-8") as f:
    metadata_list = json.load(f)

# LLM setup
llm = ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), model="gpt-3.5-turbo")

def classify_emotion(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ë‹¤ìŒ í‚¤ì›Œë“œëŠ” ê½ƒì„ ì¶”ì²œë°›ê¸° ìœ„í•œ ìƒí™©ì…ë‹ˆë‹¤:
        {keywords}

        ë‹¤ìŒ ê°ì • ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ì ì ˆí•œ í•˜ë‚˜ë§Œ ê³ ë¥´ì–´ì¤˜ (ëª©ë¡ ì™¸ ê°ì •ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ):

        ì‚¬ë‘(ê°•ë ¬í•œ), ì‚¬ë‘(ìˆœìˆ˜í•œ), ì‚¬ë‘(ì˜ì›í•œ), ì‚¬ë‘(í–‰ë³µí•œ), ì‚¬ë‘(ë”°ëœ»í•œ),
        ìŠ¬í””(í™”í•´), ìŠ¬í””(ì´ë³„), ìŠ¬í””(ê·¸ë¦¬ì›€), ìŠ¬í””(ìœ„ë¡œ),
        ì¶•í•˜(ìŠ¹ì§„), ì¶•í•˜(ê°œì—…), ì¶•í•˜(í•©ê²©), ì¶•í•˜(ìƒì¼), ì¶•í•˜(ì¶œì‚°),
        ì‘ì›(ìƒˆë¡œìš´ ì‹œì‘), ì‘ì›(í•©ê²© ê¸°ì›), ì‘ì›(ê²©ë ¤), ì‘ì›(ê¿ˆì„ í–¥í•œ ë„ì „),
        í–‰ë³µ(ì˜ì›í•œ), í–‰ë³µ(ìˆœìˆ˜í•œ), í–‰ë³µ(í•¨ê»˜í•œ), í–‰ë³µ(ë‹¤ê°€ì˜¬),
        íŠ¹ë³„í•¨(ë¹„ë°€), íŠ¹ë³„í•¨(ì‹ ë¹„), íŠ¹ë³„í•¨(ë§ˆë²•), íŠ¹ë³„í•œ(ê³ ê·€), íŠ¹ë³„í•œ(ê³ ê¸‰)

        ì •í™•íˆ ìœ„ ëª©ë¡ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•´ì¤˜. ì´ìœ ëŠ” ì“°ì§€ ë§ˆ.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({"keywords": keywords}).strip()

def expand_keywords(keywords: str) -> str:
    prompt = PromptTemplate(
        input_variables=["keywords"],
        template="""
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ: {keywords}
        ì´ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì •ê³¼ ìƒí™©ì„ í¬í•¨í•œ ìì—°ìŠ¤ëŸ½ê³  ëª¨ë“  ì˜ë„ê°€ ì˜ ì „ë‹¬ë˜ê²Œ ë¬¸ì¥ìœ¼ë¡œ í™•ì¥í•´ì¤˜.
        ë„ˆë¬´ ê¸¸ì§€ ì•Šê³ , ë§í•˜ê³ ì í•˜ëŠ” ëª©ì ì´ ì˜ ë‚˜íƒ€ë‚˜ê²Œê²Œ í•´ì¤˜.
        """
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(keywords).strip()

def get_flower_recommendations(keywords: str, top_k: int = 3):
    expanded_query = expand_keywords(keywords)
    emotion_category = classify_emotion(keywords)
    query_vector = embed_query(expanded_query)

    distances, indices = index.search(np.array(query_vector).astype("float32"), top_k * 5)

    results_with_score = []
    for i in indices[0]:
        flower = metadata_list[i]
        base_score = distances[0][list(indices[0]).index(i)]
        boost = -0.2 if emotion_category in flower.get("emotion_tags", []) else 0.0
        final_score = base_score + boost
        results_with_score.append((i, final_score))

    results_with_score.sort(key=lambda x: x[1])
    top_indices = [i for i, _ in results_with_score[:top_k]]

    results = []
    for idx in top_indices:
        flower = metadata_list[idx]
        reason = generate_reason(expanded_query, flower["description"], flower["name"])
        results.append({
            "FLW_IDX": flower["FLW_IDX"],
            "reason": reason
        })

    return {
        "recommendations": results
    }